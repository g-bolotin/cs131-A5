{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a82581-f394-4a73-b5e2-6f69af16ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb958840-6567-4be5-90b4-a541b0e16b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"student_lifestyle_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6db07235-0c42-40f4-bf64-8d3071fcde2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/05 17:27:45 WARN Utils: Your hostname, Galits-MacBook-Pro-M1.local resolves to a loopback address: 127.0.0.1; using 10.250.177.13 instead (on interface en0)\n",
      "25/05/05 17:27:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/05 17:27:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-----------------------------+-------------------+------+\n",
      "|Student_ID|Study_Hours_Per_Day|Extracurricular_Hours_Per_Day|Sleep_Hours_Per_Day|Grades|\n",
      "+----------+-------------------+-----------------------------+-------------------+------+\n",
      "|         1|                6.9|                          3.8|                8.7|  7.48|\n",
      "|         2|                5.3|                          3.5|                8.0|  6.88|\n",
      "|         3|                5.1|                          3.9|                9.2|  6.68|\n",
      "|         4|                6.5|                          2.1|                7.2|   7.2|\n",
      "|         5|                8.1|                          0.6|                6.5|  8.78|\n",
      "+----------+-------------------+-----------------------------+-------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "There are 2000 rows and 9 columns in this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/05 17:28:02 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"A5\").getOrCreate()\n",
    "df = spark.read.csv(path, header=True, inferSchema=True)\n",
    "# Columns Available:\n",
    "#    Student_ID\n",
    "#    Study_Hours_Per_Day\n",
    "#    Extracurricular_Hours_Per_Day\n",
    "#    Sleep_Hours_Per_Day\n",
    "#    Social_Hours_Per_Day\n",
    "#    Physical_Activity_Hours_Per_Day\n",
    "#    Stress_Level\n",
    "#    Gender\n",
    "#    Grades\n",
    "df.select(\"Student_ID\", \"Study_Hours_Per_Day\", \"Extracurricular_Hours_Per_Day\", \"Sleep_Hours_Per_Day\", \"Grades\").show(5)\n",
    "\n",
    "# Total number of entries:\n",
    "print(f\"\"\"There are {df.count()} rows and {len(df.columns)} columns in this dataset.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9370d-b1d1-4409-9d77-1144cd8cae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"nontrivial\" information from the dataset.\n",
    "# What can you say from the data?\n",
    "# Any interesting data trends that cannot be easily guessed or can be used to justify some hypothesis?\n",
    "\n",
    "# The trifecta: people say that in college, you can only have 2/3 of these: sleep, socialization, and study time/good grades.\n",
    "#   Based on the data, is this true?\n",
    "#   What features have the greatest impact on grades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65eef48-0f71-4f76-8886-1d53131a76d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the total number of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83acc424-bd8c-47f3-bb24-76cdf3229e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30655895-a54c-4141-9f82-632690a19e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect value ranges (mean, percentile, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e13807-7974-4c65-add2-2c13e5d41c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data (at least TWO types of nontrivial plots)\n",
    "# Consider: Violin/Box Plots, Histogram, Density Plot, Correlation Matrix, Hexagonal Binning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
